{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa939539",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U googlemaps\n",
    "pip install pandas\n",
    "pip install time\n",
    "pip install uszipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb776e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "import time\n",
    "from uszipcode import SearchEngine\n",
    "\n",
    "# Define your API key\n",
    "API_KEY = 'Your API Key'\n",
    "\n",
    "state_abbreviations = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n",
    "    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n",
    "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT',\n",
    "    'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM',\n",
    "    'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n",
    "    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "#Get zipcode and keep only the unique first three digits of the zip codes \n",
    "def get_zipcodes(state):\n",
    "    search = SearchEngine()\n",
    "    zipcodes = []\n",
    "    unique_prefixes = set()\n",
    "    for zipcode in search.by_state(state, returns=100000):\n",
    "        prefix = zipcode.zipcode[:3]\n",
    "        if prefix not in unique_prefixes:\n",
    "            unique_prefixes.add(prefix)\n",
    "            zipcodes.append(zipcode.zipcode)\n",
    "    return zipcodes\n",
    "# If you don't keep these numbers and choose to search them all, you'll get a sky-high bill for API usage \n",
    "\n",
    "\n",
    "# Get user input for the search method, state, and keywords\n",
    "search_method = input(\"Choose search method: (1) State or (2) Zip Codes: \")\n",
    "while search_method not in ['1', '2']:\n",
    "    search_method = input(\"Invalid input. Choose search method: (1) State or (2) Zip Codes: \")\n",
    "\n",
    "if search_method == '1':\n",
    "    state_name = input(\"Enter the name of the state (e.g., 'South Carolina'): \")\n",
    "    while state_name not in state_abbreviations:\n",
    "        state_name = input(\"Invalid state name. Enter the name of the state (e.g., 'South Carolina'): \")\n",
    "    search_zipcodes = get_zipcodes(state_name)\n",
    "else:\n",
    "    zip_codes_input = input(\"Enter the zip codes separated by commas (e.g., '10001, 10002'): \")\n",
    "    search_zipcodes = [zipcode.strip() for zipcode in zip_codes_input.split(',')]\n",
    "\n",
    "search_keywords = input(\"Enter the search keyword(s) separated by commas (e.g., 'self-storage, storage unit'): \")\n",
    "\n",
    "# Split the input keywords by commas and remove leading/trailing spaces\n",
    "search_keywords = [keyword.strip() for keyword in search_keywords.split(',')]\n",
    "\n",
    "\n",
    "# Initialize the Google Maps client\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "# Define a function to retrieve the place details for a given place ID\n",
    "def get_place_details(place_id):\n",
    "    place_details = gmaps.place(place_id)['result']\n",
    "    name = place_details['name']\n",
    "    rating = place_details.get('rating')\n",
    "    num_reviews = place_details.get('user_ratings_total')\n",
    "    phone_number = place_details.get('formatted_phone_number')\n",
    "    website = place_details.get('website')\n",
    "    address = place_details.get('formatted_address')\n",
    "    hours = place_details.get('opening_hours')\n",
    "    if hours:\n",
    "        hours = hours['weekday_text']\n",
    "    else:\n",
    "        hours = None\n",
    "    maps_url = f\"https://www.google.com/maps/place/?q=place_id:{place_id}\"\n",
    "    return {\n",
    "        'name': name,\n",
    "        'rating': rating,\n",
    "        'num_reviews': num_reviews,\n",
    "        'phone_number': phone_number,\n",
    "        'website': website,\n",
    "        'address': address,\n",
    "        'hours': hours,\n",
    "        'maps_url': maps_url,\n",
    "    }\n",
    "\n",
    "# Define a function to search for places in a given zip code and keyword\n",
    "def search_places(zipcode, keyword):\n",
    "    places = []\n",
    "    # Use the text search API to retrieve a list of place IDs for the given zip code and keyword\n",
    "    search_results = gmaps.places(query=f'{keyword} {zipcode}', type='establishment')\n",
    "\n",
    "    while True:\n",
    "        for result in search_results['results']:\n",
    "            # Use the place details API to retrieve the details for each place\n",
    "            place_details = get_place_details(result['place_id'])\n",
    "            places.append(place_details)\n",
    "\n",
    "        # Check if there's a next_page_token and wait 2 seconds before making the next request\n",
    "        next_page_token = search_results.get('next_page_token')\n",
    "        if next_page_token:\n",
    "            time.sleep(2)\n",
    "            search_results = gmaps.places(query=f'{keyword} {zipcode}', type='establishment', page_token=next_page_token)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return places\n",
    "\n",
    "# Initialize a set to keep track of unique place IDs\n",
    "unique_place_ids = set()\n",
    "\n",
    "# Search for places in each zip code and keyword\n",
    "results = []\n",
    "for zipcode in search_zipcodes:\n",
    "    for keyword in search_keywords:\n",
    "        places = search_places(zipcode, keyword)\n",
    "        for place in places:\n",
    "            # Check if the place ID is already in the set, if not, add it and append the place to the results\n",
    "            if place['maps_url'] not in unique_place_ids:\n",
    "                unique_place_ids.add(place['maps_url'])\n",
    "                results.append(place)\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Extract the state abbreviation and zip code from the address using regular expressions\n",
    "address_components = df['address'].str.extract(r',\\s([A-Z]{2})\\s(\\d{5}),\\sUSA')\n",
    "\n",
    "# Create new columns for the state and zip code in the DataFrame\n",
    "df['state'] = address_components[0]\n",
    "df['zipcode'] = address_components[1]\n",
    "\n",
    "# Remove the ', USA' part from the address\n",
    "df['address'] = df['address'].str.replace(', USA', '')\n",
    "\n",
    "# If the user chose to search by state, filter the results based on the selected state\n",
    "if search_method == '1':\n",
    "    state_abbreviation = state_abbreviations[state_name]\n",
    "    df = df[df['state'] == state_abbreviation]\n",
    "\n",
    "# Remove duplicates based on the 'state' column and keep the first occurrence\n",
    "df = df.drop_duplicates(subset='maps_url', keep='first')\n",
    "\n",
    "\n",
    "def get_state_by_zipcode(zipcode):\n",
    "    search = SearchEngine()\n",
    "    result = search.by_zipcode(zipcode)\n",
    "    if result:\n",
    "        return result.state\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "if search_method == '2':\n",
    "    state_name = get_state_by_zipcode(zipcode)\n",
    "\n",
    "# Export the DataFrame with all the results to an Excel file\n",
    "output_file = f\"{'_'.join(search_keywords).replace(' ', '_')}_{state_name.replace(' ', '_')}_CS.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "# Filter the DataFrame to keep only rows with a rating of 15 and below\n",
    "df_filtered = df[df['num_reviews'] <= 15]\n",
    "\n",
    "# Export the filtered DataFrame to an Excel file\n",
    "output_file_filtered = f\"{'_'.join(search_keywords).replace(' ', '_')}_{state_name.replace(' ', '_')}_CS_filtered.xlsx\"\n",
    "df_filtered.to_excel(output_file_filtered, index=False)\n",
    "\n",
    "print(f\"Results saved in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50445c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
